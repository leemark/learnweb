---
layout: guide-part
title: "Part 4: Integrating AI APIs & Services - LearnWeb"
description: "Learn how to integrate AI APIs like OpenAI, Anthropic, and others into your web applications"
subpage: true
guide_title: "AI for Web Developers"
tagline: "Part 4: Integrating AI APIs & Services"
course_id: "ai"
lesson_id: "part-4"
course_url: "index.html"
next_lesson:
  title: "Next Part: AI Tools for Development Workflow"
  url: "part-5.html"
---
<!-- Breadcrumb Navigation -->
<nav class="breadcrumb" aria-label="Breadcrumb">
    <ol class="breadcrumb-list">
        <li class="breadcrumb-item"><a href="/">Home</a></li>
        <li class="breadcrumb-item"><a href="/ai/">AI for Web Developers</a></li>
        <li class="breadcrumb-item">Part 4: Integrating AI APIs & Services</li>
    </ol>
</nav>

<!-- Lesson Meta Information -->
<div class="lesson-meta">
    <div class="lesson-meta-item">
        <span class="material-symbols-outlined">article</span>
        <span>Part 4 of 6</span>
    </div>
    <!-- Reading time will be auto-calculated by JavaScript -->
</div>

<h2>Choosing an AI API Provider</h2>

<p>Most web developers integrate AI through APIs rather than building models from scratch. Several providers offer powerful AI capabilities you can access with a few lines of code.</p>

<h3>Major AI API Providers</h3>

<svg viewBox="0 0 800 450" xmlns="http://www.w3.org/2000/svg" style="max-width: 100%; height: auto; margin: 2rem 0;" aria-labelledby="ai-providers-title" role="img">
  <title id="ai-providers-title">AI API Provider Comparison</title>

  <!-- Header -->
  <text x="400" y="30" text-anchor="middle" font-size="18" font-weight="bold" fill="#333">Major AI Providers</text>

  <!-- OpenAI -->
  <rect x="50" y="60" width="160" height="160" fill="#e8f5e9" stroke="#4caf50" stroke-width="2" rx="8"/>
  <text x="130" y="85" text-anchor="middle" font-size="15" font-weight="bold" fill="#2e7d32">OpenAI</text>
  <text x="130" y="105" text-anchor="middle" font-size="11" fill="#333">GPT-4, GPT-4o</text>
  <text x="65" y="130" font-size="10" fill="#666">✓ Most popular</text>
  <text x="65" y="147" font-size="10" fill="#666">✓ Great docs</text>
  <text x="65" y="164" font-size="10" fill="#666">✓ Vision, audio</text>
  <text x="65" y="181" font-size="10" fill="#666">✗ Can be expensive</text>
  <text x="130" y="205" text-anchor="middle" font-size="10" fill="#2e7d32" font-weight="bold">Best for: General purpose</text>

  <!-- Anthropic -->
  <rect x="230" y="60" width="160" height="160" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2" rx="8"/>
  <text x="310" y="85" text-anchor="middle" font-size="15" font-weight="bold" fill="#6a1b9a">Anthropic</text>
  <text x="310" y="105" text-anchor="middle" font-size="11" fill="#333">Claude 3.5 Sonnet</text>
  <text x="245" y="130" font-size="10" fill="#666">✓ Excellent reasoning</text>
  <text x="245" y="147" font-size="10" fill="#666">✓ 200K context</text>
  <text x="245" y="164" font-size="10" fill="#666">✓ Strong at code</text>
  <text x="245" y="181" font-size="10" fill="#666">✗ Newer, less docs</text>
  <text x="310" y="205" text-anchor="middle" font-size="10" fill="#6a1b9a" font-weight="bold">Best for: Complex tasks</text>

  <!-- Google -->
  <rect x="410" y="60" width="160" height="160" fill="#e3f2fd" stroke="#1976d2" stroke-width="2" rx="8"/>
  <text x="490" y="85" text-anchor="middle" font-size="15" font-weight="bold" fill="#1565c0">Google</text>
  <text x="490" y="105" text-anchor="middle" font-size="11" fill="#333">Gemini Pro</text>
  <text x="425" y="130" font-size="10" fill="#666">✓ Multimodal</text>
  <text x="425" y="147" font-size="10" fill="#666">✓ Free tier</text>
  <text x="425" y="164" font-size="10" fill="#666">✓ Fast</text>
  <text x="425" y="181" font-size="10" fill="#666">✗ Rate limits</text>
  <text x="490" y="205" text-anchor="middle" font-size="10" fill="#1565c0" font-weight="bold">Best for: Prototyping</text>

  <!-- Open Source / Self-hosted -->
  <rect x="590" y="60" width="160" height="160" fill="#fff3e0" stroke="#ff9800" stroke-width="2" rx="8"/>
  <text x="670" y="85" text-anchor="middle" font-size="15" font-weight="bold" fill="#e65100">Open Source</text>
  <text x="670" y="105" text-anchor="middle" font-size="11" fill="#333">Llama, Mistral</text>
  <text x="605" y="130" font-size="10" fill="#666">✓ Full control</text>
  <text x="605" y="147" font-size="10" fill="#666">✓ Privacy</text>
  <text x="605" y="164" font-size="10" fill="#666">✓ No API costs</text>
  <text x="605" y="181" font-size="10" fill="#666">✗ Hosting complexity</text>
  <text x="670" y="205" text-anchor="middle" font-size="10" fill="#e65100" font-weight="bold">Best for: Privacy needs</text>

  <!-- Specialized -->
  <rect x="140" y="250" width="520" height="150" fill="#fce4ec" stroke="#c2185b" stroke-width="2" rx="8"/>
  <text x="400" y="275" text-anchor="middle" font-size="15" font-weight="bold" fill="#880e4f">Specialized Services</text>

  <text x="160" y="305" font-size="12" fill="#333" font-weight="bold">• Hugging Face:</text>
  <text x="170" y="322" font-size="10" fill="#666">Thousands of models (translation, summarization, etc.)</text>

  <text x="160" y="345" font-size="12" fill="#333" font-weight="bold">• Cohere:</text>
  <text x="170" y="362" font-size="10" fill="#666">Embeddings and semantic search</text>

  <text x="160" y="385" font-size="12" fill="#333" font-weight="bold">• Stability AI:</text>
  <text x="170" y="402" font-size="10" fill="#666">Image generation (Stable Diffusion)</text>

  <text x="450" y="305" font-size="12" fill="#333" font-weight="bold">• Replicate:</text>
  <text x="460" y="322" font-size="10" fill="#666">Run open source models via API</text>

  <text x="450" y="345" font-size="12" fill="#333" font-weight="bold">• ElevenLabs:</text>
  <text x="460" y="362" font-size="10" fill="#666">Text-to-speech and voice cloning</text>

  <text x="450" y="385" font-size="12" fill="#333" font-weight="bold">• AssemblyAI:</text>
  <text x="460" y="402" font-size="10" fill="#666">Speech-to-text transcription</text>
</svg>

<h2>Getting Started with OpenAI API</h2>

<p>Let's walk through a complete example using OpenAI's API (the most popular choice).</p>

<h3>Step 1: Get API Key</h3>

<ol>
  <li>Sign up at <code>platform.openai.com</code></li>
  <li>Navigate to API keys section</li>
  <li>Create a new API key</li>
  <li>Store it securely (never commit to GitHub!)</li>
</ol>

<h3>Step 2: Install SDK</h3>

<pre><code># Node.js
npm install openai

# Python
pip install openai</code></pre>

<h3>Step 3: Basic Implementation</h3>

<pre><code>// Node.js/JavaScript example
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, // Store in environment variable
});

async function generateResponse(userMessage) {
  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "You are a helpful customer support assistant."
        },
        {
          role: "user",
          content: userMessage
        }
      ],
      temperature: 0.7,
      max_tokens: 500,
    });

    return completion.choices[0].message.content;
  } catch (error) {
    console.error('OpenAI API error:', error);
    throw error;
  }
}

// Usage
const response = await generateResponse("How do I reset my password?");
console.log(response);</code></pre>

<h3>Key Parameters Explained</h3>

<ul>
  <li><strong>model</strong> – Which AI model to use (gpt-4o, gpt-4-turbo, gpt-3.5-turbo, etc.)</li>
  <li><strong>messages</strong> – Array of conversation messages with roles (system, user, assistant)</li>
  <li><strong>temperature</strong> – Randomness/creativity (0 = deterministic, 2 = very creative)</li>
  <li><strong>max_tokens</strong> – Maximum length of response (limits cost)</li>
  <li><strong>top_p</strong> – Alternative to temperature for controlling randomness</li>
  <li><strong>presence_penalty</strong> – Encourages talking about new topics (-2 to 2)</li>
  <li><strong>frequency_penalty</strong> – Reduces repetition (-2 to 2)</li>
</ul>

<h2>Architecture Patterns for AI Integration</h2>

<h3>Pattern 1: Client-Side Direct (Simple but Limited)</h3>

<svg viewBox="0 0 700 200" xmlns="http://www.w3.org/2000/svg" style="max-width: 100%; height: auto; margin: 2rem 0;" aria-labelledby="client-direct-title" role="img">
  <title id="client-direct-title">Client-Side Direct AI Integration</title>

  <rect x="50" y="70" width="150" height="60" fill="#e3f2fd" stroke="#1976d2" stroke-width="2" rx="8"/>
  <text x="125" y="95" text-anchor="middle" font-size="14" font-weight="bold" fill="#1565c0">Browser</text>
  <text x="125" y="115" text-anchor="middle" font-size="11" fill="#333">User App</text>

  <path d="M 200 100 L 300 100" stroke="#666" stroke-width="3" marker-end="url(#arrowright)"/>
  <text x="250" y="90" text-anchor="middle" font-size="10" fill="#c62828">⚠️ API key exposed!</text>

  <rect x="300" y="70" width="150" height="60" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2" rx="8"/>
  <text x="375" y="95" text-anchor="middle" font-size="14" font-weight="bold" fill="#6a1b9a">OpenAI API</text>

  <text x="500" y="100" font-size="11" fill="#c62828" font-weight="bold">❌ Not recommended</text>
  <text x="500" y="120" font-size="10" fill="#666">Security risk!</text>

  <defs>
    <marker id="arrowright" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <polygon points="0 0, 10 3, 0 6" fill="#666"/>
    </marker>
  </defs>
</svg>

<p><strong>Why avoid:</strong> Your API key is exposed in client code, allowing anyone to use (and abuse) your quota.</p>

<h3>Pattern 2: Backend Proxy (Recommended)</h3>

<svg viewBox="0 0 800 250" xmlns="http://www.w3.org/2000/svg" style="max-width: 100%; height: auto; margin: 2rem 0;" aria-labelledby="backend-proxy-title" role="img">
  <title id="backend-proxy-title">Backend Proxy Architecture</title>

  <!-- Frontend -->
  <rect x="50" y="95" width="120" height="60" fill="#e3f2fd" stroke="#1976d2" stroke-width="2" rx="8"/>
  <text x="110" y="120" text-anchor="middle" font-size="13" font-weight="bold" fill="#1565c0">Frontend</text>
  <text x="110" y="138" text-anchor="middle" font-size="10" fill="#333">Browser</text>

  <path d="M 170 125 L 250 125" stroke="#4caf50" stroke-width="3" marker-end="url(#arrowgreen)"/>
  <text x="210" y="115" text-anchor="middle" font-size="10" fill="#2e7d32">User request</text>

  <!-- Backend -->
  <rect x="250" y="95" width="140" height="60" fill="#e8f5e9" stroke="#388e3c" stroke-width="2" rx="8"/>
  <text x="320" y="115" text-anchor="middle" font-size="13" font-weight="bold" fill="#2e7d32">Your Backend</text>
  <text x="320" y="133" text-anchor="middle" font-size="10" fill="#333">Node/Python</text>

  <!-- Auth & validation box -->
  <rect x="255" y="165" width="130" height="50" fill="#fff3e0" stroke="#ff9800" stroke-width="1" rx="4"/>
  <text x="320" y="183" text-anchor="middle" font-size="9" fill="#e65100">✓ Auth user</text>
  <text x="320" y="196" text-anchor="middle" font-size="9" fill="#e65100">✓ Rate limit</text>
  <text x="320" y="209" text-anchor="middle" font-size="9" fill="#e65100">✓ Validate input</text>

  <path d="M 390 125 L 470 125" stroke="#4caf50" stroke-width="3" marker-end="url(#arrowgreen)"/>
  <text x="430" y="115" text-anchor="middle" font-size="10" fill="#2e7d32">API call</text>
  <text x="430" y="140" text-anchor="middle" font-size="9" fill="#666">(API key secure)</text>

  <!-- AI Service -->
  <rect x="470" y="95" width="140" height="60" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2" rx="8"/>
  <text x="540" y="120" text-anchor="middle" font-size="13" font-weight="bold" fill="#6a1b9a">AI API</text>
  <text x="540" y="138" text-anchor="middle" font-size="10" fill="#333">OpenAI/etc</text>

  <text x="670" y="125" font-size="11" fill="#2e7d32" font-weight="bold">✓ Secure!</text>

  <defs>
    <marker id="arrowgreen" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <polygon points="0 0, 10 3, 0 6" fill="#4caf50"/>
    </marker>
  </defs>
</svg>

<p><strong>Implementation example:</strong></p>

<pre><code>// Backend API endpoint (Express.js)
import express from 'express';
import OpenAI from 'openai';

const app = express();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post('/api/chat', async (req, res) => {
  // 1. Authenticate user
  const user = await authenticateUser(req);
  if (!user) {
    return res.status(401).json({ error: 'Unauthorized' });
  }

  // 2. Rate limiting
  if (await isRateLimited(user.id)) {
    return res.status(429).json({ error: 'Too many requests' });
  }

  // 3. Validate and sanitize input
  const { message } = req.body;
  if (!message || message.length > 1000) {
    return res.status(400).json({ error: 'Invalid message' });
  }

  try {
    // 4. Call OpenAI API
    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user", content: message }
      ],
      max_tokens: 500,
    });

    // 5. Log usage for billing
    await logUsage(user.id, completion.usage);

    // 6. Return response
    res.json({
      response: completion.choices[0].message.content,
      usage: completion.usage
    });
  } catch (error) {
    console.error('OpenAI error:', error);
    res.status(500).json({ error: 'AI service unavailable' });
  }
});

// Frontend code
async function askAI(message) {
  const response = await fetch('/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ message }),
  });

  if (!response.ok) throw new Error('Request failed');
  return response.json();
}</code></pre>

<h3>Pattern 3: Streaming Responses</h3>

<p>For better UX, stream AI responses token-by-token instead of waiting for the complete response.</p>

<pre><code>// Backend - streaming endpoint
app.post('/api/chat/stream', async (req, res) => {
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');

  const stream = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [{ role: "user", content: req.body.message }],
    stream: true,
  });

  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    if (content) {
      res.write(`data: ${JSON.stringify({ content })}\n\n`);
    }
  }

  res.write('data: [DONE]\n\n');
  res.end();
});

// Frontend - receive streaming response
async function streamAIResponse(message) {
  const response = await fetch('/api/chat/stream', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ message }),
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { value, done } = await reader.read();
    if (done) break;

    const chunk = decoder.decode(value);
    const lines = chunk.split('\n');

    for (const line of lines) {
      if (line.startsWith('data: ')) {
        const data = line.slice(6);
        if (data === '[DONE]') return;

        const parsed = JSON.parse(data);
        updateUI(parsed.content); // Update UI incrementally
      }
    }
  }
}</code></pre>

<h2>Cost Management Strategies</h2>

<p>AI API costs can add up quickly. Implement these strategies to control expenses:</p>

<h3>1. Caching</h3>

<pre><code>import Redis from 'ioredis';
const redis = new Redis();

async function getCachedAIResponse(prompt) {
  // Check cache first
  const cached = await redis.get(`ai:${hash(prompt)}`);
  if (cached) return JSON.parse(cached);

  // Call AI if not cached
  const response = await openai.chat.completions.create({...});
  const result = response.choices[0].message.content;

  // Cache for 1 hour
  await redis.setex(`ai:${hash(prompt)}`, 3600, JSON.stringify(result));

  return result;
}</code></pre>

<h3>2. Token Limits & Truncation</h3>

<pre><code>import { encoding_for_model } from 'tiktoken';

function truncateToTokenLimit(text, maxTokens = 4000) {
  const encoding = encoding_for_model('gpt-4');
  const tokens = encoding.encode(text);

  if (tokens.length <= maxTokens) return text;

  // Truncate and decode back to text
  const truncated = tokens.slice(0, maxTokens);
  return encoding.decode(truncated);
}</code></pre>

<h3>3. Model Selection</h3>

<pre><code>// Use cheaper models for simple tasks
function chooseModel(taskComplexity) {
  if (taskComplexity === 'simple') {
    return 'gpt-3.5-turbo'; // $0.0005 per 1K tokens
  } else {
    return 'gpt-4o'; // $0.0025-$0.01 per 1K tokens
  }
}</code></pre>

<h3>4. Rate Limiting</h3>

<pre><code>import rateLimit from 'express-rate-limit';

const aiRateLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 50, // Limit each user to 50 requests per window
  message: 'Too many AI requests, please try again later.',
});

app.post('/api/chat', aiRateLimiter, async (req, res) => {
  // ... handle request
});</code></pre>

<h2>Error Handling Best Practices</h2>

<pre><code>async function robustAICall(prompt, options = {}) {
  const maxRetries = 3;
  let lastError;

  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const response = await openai.chat.completions.create({
        ...options,
        messages: [{ role: "user", content: prompt }],
      });

      return response.choices[0].message.content;

    } catch (error) {
      lastError = error;

      // Don't retry on certain errors
      if (error.status === 400) {
        throw new Error('Invalid request: ' + error.message);
      }

      // Retry on rate limits with exponential backoff
      if (error.status === 429) {
        const delay = Math.pow(2, attempt) * 1000;
        console.log(`Rate limited, retrying in ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }

      // Retry on server errors
      if (error.status >= 500) {
        console.log(`Server error, retrying attempt ${attempt + 1}...`);
        await new Promise(resolve => setTimeout(resolve, 1000));
        continue;
      }

      throw error;
    }
  }

  throw new Error(`Failed after ${maxRetries} attempts: ${lastError.message}`);
}</code></pre>

<h3>Key Takeaways</h3>

<ul>
  <li>Major AI providers: OpenAI (most popular), Anthropic (best reasoning), Google (free tier), open source (privacy/control).</li>
  <li>Never expose API keys in client code—always use a backend proxy.</li>
  <li>Backend proxy pattern: frontend → your server → AI API (enables auth, rate limiting, input validation).</li>
  <li>Stream responses for better UX—show text as it's generated instead of waiting.</li>
  <li>Manage costs: cache responses, set token limits, choose cheaper models for simple tasks, implement rate limiting.</li>
  <li>Robust error handling: retry with exponential backoff for rate limits, don't retry on client errors (400s).</li>
  <li>Key parameters: model, temperature (randomness), max_tokens (cost control), messages (conversation context).</li>
  <li>Monitor usage and set budget alerts to avoid surprise bills.</li>
  <li>Log all AI requests for debugging, analytics, and compliance.</li>
  <li>Implement timeouts to prevent hanging requests.</li>
</ul>

<p>Next, let's explore AI-powered development tools that can accelerate your workflow.</p>

<!-- Mark as Complete -->
<div class="lesson-completion">
    <label class="lesson-completion-label">
        <div class="lesson-completion-checkbox">
            <span class="material-symbols-outlined">check</span>
        </div>
        <span class="lesson-completion-text">Mark this lesson as complete</span>
    </label>
</div>
